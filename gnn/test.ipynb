{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['store', 'double', 'TMP_VAR(D)', 'TMP_FUNCTION_NAME', ';', 'load', 'TMP_VAR', 'double', 'TMP_VAR(D)', ';', 'assignment', 'TMP_POINTER_MEMBER', 'TMP_FUNCTION_NAME', ';', 'assignment', 'TMP_VAR', 'TMP_FUNCTION_NAME', ';', 'math_op', 'TMP_VAR', 'TMP_NUMBER', '/', 'TMP_FUNCTION_NAME', ';', 'function_call', 'GSL_MIN_DBL', ['TMP_VAR', 'TMP_VAR'], ';', 'phi', 'TMP_VAR', 'TMP_VAR: TMP_VAR, TMP_VAR: TMP_VAR, TMP_VAR: TMP_VAR, TMP_VAR: TMP_VAR, TMP_VAR: TMP_VAR', ';']\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from data import prepare_data_vocab, live_feat\n",
    "from torch.nn.utils.rnn import unpack_sequence\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx, idx_to_word, data, data_emb = prepare_data_vocab(\"data\", func=live_feat, function_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(INFUNCTION_VAR * INFUNCTION_VAR)TMP_FUNCTION_NAME\t(INFUNCTION_VAR *)TMP_VAR\t*\t+\t-\t-TMP_NUMBER\t-TMP_VAR\t/\t;\tINFUNCTION_VAR\tINFUNCTION_VAR.INFUNCTION_VAR\tTMP_FUNCTION_ARG_1\tTMP_FUNCTION_ARG_10\tTMP_FUNCTION_ARG_11\tTMP_FUNCTION_ARG_2\tTMP_FUNCTION_ARG_3\tTMP_FUNCTION_ARG_4\tTMP_FUNCTION_ARG_5\tTMP_FUNCTION_ARG_6\tTMP_FUNCTION_ARG_7\tTMP_FUNCTION_ARG_8\tTMP_FUNCTION_ARG_9\tTMP_FUNCTION_NAME\tTMP_NUMBER\tTMP_POINTER_MEMBER\tTMP_VAR\tTMP_VAR(INFUNCTION_VAR)\tTMP_VAR(TMP_FUNCTION_NAME)\tassignment\tchar\tdouble\tfloat\tfunction_call\tgsl_error\tint\tload\tmath_op\tphi\tsize_t\tstore\t\n",
      "----------\n",
      " 40\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in idx_to_word.keys():\n",
    "    print(idx_to_word[i], end='\\t')\n",
    "    cnt+= 1\n",
    "\n",
    "print(\"\\n----------\\n\",cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define InputEncoder (RNN) and GNN\n",
    "in_dim = 8\n",
    "hidden_dim = 64\n",
    "num_layers = 7\n",
    "bidirectional = True\n",
    "out_dim    = 128\n",
    "\n",
    "int_dir = 2 if bidirectional else 1\n",
    "\n",
    "bb_enc = InputEncoder(word_to_idx, \n",
    "                      in_dim=in_dim, \n",
    "                      hidden_dim=hidden_dim, \n",
    "                      num_layers=num_layers, \n",
    "                      bidirectional=bidirectional)\n",
    " \n",
    "gnn = GNNModel(in_dim=int_dir*hidden_dim,\n",
    "               out_dim=out_dim,\n",
    "               layer_dims=[16, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 8\n",
    "hidden_dim = 16\n",
    "num_layers = 7\n",
    "bidirectional = True\n",
    "out_dim    = 32\n",
    "\n",
    "int_dir = 2 if bidirectional else 1\n",
    "integrated = IntegratedModel(word_to_idx, \n",
    "                      in_dim_lstm=in_dim, \n",
    "                      hidden_dim=hidden_dim, \n",
    "                      num_layers=num_layers, \n",
    "                      bidirectional=bidirectional,\n",
    "                        out_dim=out_dim,\n",
    "                        layer_dims=[16, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data)==len(data_emb)\n",
    "for i in range(len(data)):\n",
    "    assert len(data[i][2])==len(data_emb[i][1])\n",
    "\n",
    "#define InputEncoder (RNN) and GNN\n",
    "in_dim = 8\n",
    "hidden_dim = 16\n",
    "num_layers = 7\n",
    "bidirectional = True\n",
    "out_dim    = 16\n",
    "\n",
    "int_dir = 2 if bidirectional else 1\n",
    "\n",
    "bb_enc = InputEncoder(word_to_idx, \n",
    "                      in_dim=in_dim, \n",
    "                      hidden_dim=hidden_dim, \n",
    "                      num_layers=num_layers, \n",
    "                      bidirectional=bidirectional)\n",
    " \n",
    "gnn = GNNModel(in_dim=int_dir*hidden_dim,\n",
    "               out_dim=out_dim,\n",
    "               layer_dims=[16, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_node_embeddings = []\n",
    "new_data_emb = []\n",
    "for graph in data_emb:\n",
    "    edge_index, node_embs = graph\n",
    "    #if torch.tensor(edge_index).shape[0]==0:\n",
    "    if len(edge_index) != 0:\n",
    "        edge_index = torch.tensor(edge_index).T\n",
    "    else:\n",
    "        edge_index = torch.tensor([[0],[0]])\n",
    "    \n",
    "    out, h, c = bb_enc(node_embs)\n",
    "    node_feats = torch.vstack([k[-1] for k in unpack_sequence(out)])\n",
    "\n",
    "    assert node_feats.shape == (len(node_embs), int_dir*hidden_dim)\n",
    "\n",
    "            #Step 2: gnn forward pass\n",
    "    graph = Data(edge_index=edge_index,\n",
    "                        x=node_feats)\n",
    "    initial_node_embeddings.append(torch.rand((graph.num_nodes, out_dim), requires_grad=True))\n",
    "    new_data_emb.append([edge_index, node_embs, initial_node_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, node_embs = data_emb[0]\n",
    "#if torch.tensor(edge_index).shape[0]==0:\n",
    "\n",
    "if len(edge_index) != 0:\n",
    "    edge_index = torch.tensor(edge_index).T\n",
    "else:\n",
    "    edge_index = torch.tensor([[0],[0]])\n",
    "            \n",
    "        \n",
    "out, h, c = bb_enc(node_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0196, -0.0244, -0.0206,  ...,  0.0122,  0.0122, -0.0505],\n",
       "        [ 0.0196, -0.0243, -0.0206,  ...,  0.0122,  0.0119, -0.0505],\n",
       "        [ 0.0180, -0.0271, -0.0214,  ...,  0.0167,  0.0171, -0.0428],\n",
       "        ...,\n",
       "        [ 0.0216, -0.0767, -0.0376,  ...,  0.0159,  0.0168, -0.0404],\n",
       "        [ 0.0170, -0.0873, -0.0395,  ...,  0.0135,  0.0149, -0.0244],\n",
       "        [ 0.0171, -0.0872, -0.0395,  ...,  0.0135,  0.0148, -0.0244]],\n",
       "       grad_fn=<CatBackward0>), batch_sizes=tensor([14,  6,  6,  2,  2]), sorted_indices=tensor([ 0,  6,  2,  4,  8, 10,  1,  3,  5,  7,  9, 11, 12, 13]), unsorted_indices=tensor([ 0,  6,  2,  7,  3,  8,  1,  9,  4, 10,  5, 11, 12, 13]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -0.0054456745, Mean: 0.0004139719, Max: 0.0070569017 |#| For 1 functions: Epoch 1/100, Average Loss: 0.0318206660\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 11 is out of bounds for dimension 0 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#random_indices = random.sample(range(0, 128), 8)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39mx \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m((\u001b[38;5;28mint\u001b[39m)(int_dir\u001b[38;5;241m*\u001b[39mhidden_dim\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m))]        \n\u001b[0;32m---> 35\u001b[0m gnn_output, node_feats \u001b[38;5;241m=\u001b[39m \u001b[43mintegrated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m node_feats\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mlen\u001b[39m(node_embs), int_dir\u001b[38;5;241m*\u001b[39mhidden_dim)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Unsupervised loss (dummy loss for illustration)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#loss = criterion(output, random_target[j])\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Home/BU/HLS/GNN/gnnexamples/gnn/model.py:126\u001b[0m, in \u001b[0;36mIntegratedModel.forward\u001b[0;34m(self, node_sequences, edge_index)\u001b[0m\n\u001b[1;32m    123\u001b[0m node_feats[:,\u001b[38;5;241m16\u001b[39m:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    124\u001b[0m graph \u001b[38;5;241m=\u001b[39m Data(edge_index\u001b[38;5;241m=\u001b[39medge_index,\n\u001b[1;32m    125\u001b[0m                 x\u001b[38;5;241m=\u001b[39mnode_feats)\n\u001b[0;32m--> 126\u001b[0m gnn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gnn_output, out_act\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Home/BU/HLS/GNN/gnnexamples/gnn/model.py:44\u001b[0m, in \u001b[0;36mGNNModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     41\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers:\n\u001b[0;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43ml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[1;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    208\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:100\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     99\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[0;32m--> 100\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    102\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/utils/scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     77\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 11 is out of bounds for dimension 0 with size 11"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(integrated.parameters(), lr=0.01)\n",
    "torch.nn.utils.clip_grad_norm_(integrated.parameters(), max_norm=1)\n",
    "\n",
    "epoch_num = 100\n",
    "# Training loop\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    j = -1\n",
    "    Min = 0\n",
    "    Max = 0\n",
    "    Mean = 0\n",
    "    for graph in data_emb:\n",
    "        optimizer.zero_grad()\n",
    "        j += 1\n",
    "        edge_index, node_embs = graph\n",
    "        #if torch.tensor(edge_index).shape[0]==0:\n",
    "        if len(edge_index) != 0:\n",
    "            edge_index = torch.tensor(edge_index).T\n",
    "        else:\n",
    "            edge_index = torch.tensor([[0],[0]])\n",
    "            \n",
    "        \n",
    "       \n",
    "        #random_indices = random.sample(range(0, 128), 8)\n",
    "        random_indices = [10*x for x in range((int)(int_dir*hidden_dim/10))]        \n",
    "        \n",
    "\n",
    "        gnn_output, node_feats = integrated(node_embs, edge_index)\n",
    "        \n",
    "        assert node_feats.shape == (len(node_embs), int_dir*hidden_dim)\n",
    "       \n",
    "        \n",
    "        \n",
    "        # Unsupervised loss (dummy loss for illustration)\n",
    "        #loss = criterion(output, random_target[j])\n",
    "        loss = criterion(gnn_output, node_feats)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_loss += loss.item()\n",
    "        total_items += node_feats.shape[0]\n",
    "\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        Min += node_feats.min()/len(node_feats)\n",
    "        Mean += node_feats.mean()/len(node_feats)\n",
    "        Max += node_feats.max()/len(node_feats)\n",
    "        \n",
    "        if epoch%2==0 or epoch==epoch_num-1:\n",
    "            avg_loss = total_loss / (j+1)\n",
    "            print(f\"Min: {Min:.10f}, Mean: {Mean:.10f}, Max: {Max:.10f}\", end=' |#| ')\n",
    "            print(f'For {j+1} functions: Epoch {epoch+1}/{epoch_num}, Average Loss: {avg_loss:.10f}', end='\\r')\n",
    "\n",
    "        #total_loss += unsupervised_loss.item()\n",
    "\n",
    "    # Print or log the average loss for monitoring\n",
    "    if epoch%2==0 or epoch==epoch_num-1:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 2, 3]),\n",
       " tensor([1]),\n",
       " tensor([6, 1, 3]),\n",
       " tensor([1]),\n",
       " tensor([6, 2, 3]),\n",
       " tensor([1]),\n",
       " tensor([6, 0, 0, 0, 2]),\n",
       " tensor([1]),\n",
       " tensor([6, 2, 3]),\n",
       " tensor([1]),\n",
       " tensor([6, 2, 3]),\n",
       " tensor([1]),\n",
       " tensor([6]),\n",
       " tensor([4])]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max:  128\n",
      "Min:  2\n"
     ]
    }
   ],
   "source": [
    "min = 10000\n",
    "max = 0\n",
    "for graph in data_emb:\n",
    "    edge_index, node_embs = graph\n",
    "    if len(edge_index) != 0:\n",
    "        if len(node_embs)>max:\n",
    "            max = len(node_embs)\n",
    "        if len(node_embs)<min:\n",
    "            min = len(node_embs)\n",
    "print(\"Max: \", max)\n",
    "print(\"Min: \", min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 578 functions: Epoch 1/300, Average Loss: 0.08449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [99], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m total_items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 42\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch\u001b[38;5;241m==\u001b[39mepoch_num\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(gnn.parameters(), lr=0.01)\n",
    "\n",
    "epoch_num = 300\n",
    "# Training loop\n",
    "\n",
    "random_target = torch.rand((len(data_emb), 1, out_dim))\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    j = -1\n",
    "    for graph in data_emb:\n",
    "        j += 1\n",
    "        edge_index, node_embs = graph\n",
    "        #if torch.tensor(edge_index).shape[0]==0:\n",
    "        if len(edge_index) != 0:\n",
    "            edge_index = torch.tensor(edge_index).T\n",
    "        else:\n",
    "            edge_index = torch.tensor([[0],[0]])\n",
    "            \n",
    "        \n",
    "        out, h, c = bb_enc(node_embs)\n",
    "        node_feats = torch.vstack([k[-1] for k in unpack_sequence(out)])\n",
    "\n",
    "        assert node_feats.shape == (len(node_embs), int_dir*hidden_dim)\n",
    "\n",
    "                #Step 2: gnn forward pass\n",
    "        graph = Data(edge_index=edge_index,\n",
    "                            x=node_feats)\n",
    "        \n",
    "        output = gnn(graph)\n",
    "        # Unsupervised loss (dummy loss for illustration)\n",
    "        loss = criterion(output, random_target[j])\n",
    "        #loss = criterion(output, initial_node_embeddings[j])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_loss  += loss.item()\n",
    "        total_items += graph.x.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch%10==0 or epoch==epoch_num-1:\n",
    "            avg_loss = total_loss / len(data_emb)\n",
    "            print(f'For {j+1} functions: Epoch {epoch+1}/{epoch_num}, Average Loss: {avg_loss:.5f}', end='\\r')\n",
    "\n",
    "        #total_loss += unsupervised_loss.item()\n",
    "\n",
    "    # Print or log the average loss for monitoring\n",
    "    if epoch%10==0 or epoch==epoch_num-1:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6942e-06,  3.6233e-06, -7.3788e-04, -4.4494e-05,  3.6724e-08,\n",
       "         -7.6004e-01, -2.7473e-03,  5.2556e-04,  3.6020e-06, -4.5144e-05,\n",
       "         -9.2002e-07,  6.8339e-02, -2.3965e-04,  1.6933e-03, -1.9910e-04,\n",
       "         -2.3565e-04,  4.8033e-02,  9.4108e-02, -7.9327e-02,  1.0815e-01,\n",
       "          1.6961e-02, -1.9245e-02, -3.6383e-03,  1.5153e-01, -4.3944e-02,\n",
       "         -2.2803e-02, -7.2129e-02,  7.6061e-02, -3.1655e-02, -1.4341e-01,\n",
       "          9.2256e-02, -1.8506e-01],\n",
       "        [-1.6942e-06,  3.6233e-06, -7.3788e-04, -4.4494e-05,  3.6724e-08,\n",
       "         -7.6004e-01, -2.7473e-03,  5.2556e-04,  3.6020e-06, -4.5144e-05,\n",
       "         -9.2002e-07,  6.8339e-02, -2.3965e-04,  1.6933e-03, -1.9910e-04,\n",
       "         -2.3565e-04,  4.8033e-02,  9.4108e-02, -7.9327e-02,  1.0815e-01,\n",
       "          1.6961e-02, -1.9245e-02, -3.6383e-03,  1.5153e-01, -4.3944e-02,\n",
       "         -2.2803e-02, -7.2129e-02,  7.6061e-02, -3.1655e-02, -1.4341e-01,\n",
       "          9.2256e-02, -1.8506e-01],\n",
       "        [-1.6942e-06,  3.6233e-06, -7.3788e-04, -4.4494e-05,  3.6724e-08,\n",
       "         -7.6004e-01, -2.7473e-03,  5.2556e-04,  3.6020e-06, -4.5144e-05,\n",
       "         -9.2002e-07,  6.8339e-02, -2.3965e-04,  1.6933e-03, -1.9910e-04,\n",
       "         -2.3565e-04,  4.8033e-02,  9.4108e-02, -7.9327e-02,  1.0815e-01,\n",
       "          1.6961e-02, -1.9245e-02, -3.6383e-03,  1.5153e-01, -4.3944e-02,\n",
       "         -2.2803e-02, -7.2129e-02,  7.6061e-02, -3.1655e-02, -1.4341e-01,\n",
       "          9.2256e-02, -1.8506e-01],\n",
       "        [-1.1700e-06,  7.5764e-07, -1.3019e-04, -1.6162e-05,  1.2953e-08,\n",
       "         -9.9966e-01, -5.8828e-03,  7.0171e-05,  7.6033e-07, -1.3339e-05,\n",
       "         -1.7024e-07,  1.5966e-01, -1.4535e-04,  3.6517e-04, -2.3754e-05,\n",
       "         -5.3328e-05,  5.4880e-02,  8.5114e-02, -7.9509e-02,  1.1086e-01,\n",
       "          3.5674e-02, -3.6125e-02, -9.2807e-03,  1.8709e-01, -3.2892e-02,\n",
       "         -3.5655e-02, -5.6451e-02,  6.7804e-02, -1.4693e-02, -1.3732e-01,\n",
       "          1.0297e-01, -1.9425e-01],\n",
       "        [-1.6942e-06,  3.6233e-06, -7.3788e-04, -4.4494e-05,  3.6724e-08,\n",
       "         -7.6004e-01, -2.7473e-03,  5.2556e-04,  3.6020e-06, -4.5144e-05,\n",
       "         -9.2002e-07,  6.8339e-02, -2.3965e-04,  1.6933e-03, -1.9910e-04,\n",
       "         -2.3565e-04,  4.8033e-02,  9.4108e-02, -7.9327e-02,  1.0815e-01,\n",
       "          1.6961e-02, -1.9245e-02, -3.6383e-03,  1.5153e-01, -4.3944e-02,\n",
       "         -2.2803e-02, -7.2129e-02,  7.6061e-02, -3.1655e-02, -1.4341e-01,\n",
       "          9.2256e-02, -1.8506e-01]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight grad norm: 4.2484352889005095e-05\n",
      "lstm.weight_ih_l0 grad norm: 0.0003254949115216732\n",
      "lstm.weight_hh_l0 grad norm: 7.605506834806874e-05\n",
      "lstm.bias_ih_l0 grad norm: 0.0003012344823218882\n",
      "lstm.bias_hh_l0 grad norm: 0.0003012344823218882\n",
      "lstm.weight_ih_l0_reverse grad norm: 0.00032709658262319863\n",
      "lstm.weight_hh_l0_reverse grad norm: 7.603189442306757e-05\n",
      "lstm.bias_ih_l0_reverse grad norm: 0.000313809810904786\n",
      "lstm.bias_hh_l0_reverse grad norm: 0.000313809810904786\n",
      "lstm.weight_ih_l1 grad norm: 0.000558680621907115\n",
      "lstm.weight_hh_l1 grad norm: 0.00022624272969551384\n",
      "lstm.bias_ih_l1 grad norm: 0.0010487716645002365\n",
      "lstm.bias_hh_l1 grad norm: 0.0010487715480849147\n",
      "lstm.weight_ih_l1_reverse grad norm: 0.0004790965758729726\n",
      "lstm.weight_hh_l1_reverse grad norm: 0.00016279509873129427\n",
      "lstm.bias_ih_l1_reverse grad norm: 0.0009165560477413237\n",
      "lstm.bias_hh_l1_reverse grad norm: 0.0009165561059489846\n",
      "lstm.weight_ih_l2 grad norm: 0.0014243311015889049\n",
      "lstm.weight_hh_l2 grad norm: 0.0006491430685855448\n",
      "lstm.bias_ih_l2 grad norm: 0.0031884764321148396\n",
      "lstm.bias_hh_l2 grad norm: 0.003188476664945483\n",
      "lstm.weight_ih_l2_reverse grad norm: 0.0012144839856773615\n",
      "lstm.weight_hh_l2_reverse grad norm: 0.000511831371113658\n",
      "lstm.bias_ih_l2_reverse grad norm: 0.0027420001570135355\n",
      "lstm.bias_hh_l2_reverse grad norm: 0.0027420001570135355\n",
      "lstm.weight_ih_l3 grad norm: 0.005598713643848896\n",
      "lstm.weight_hh_l3 grad norm: 0.002777466317638755\n",
      "lstm.bias_ih_l3 grad norm: 0.012291979975998402\n",
      "lstm.bias_hh_l3 grad norm: 0.012291979975998402\n",
      "lstm.weight_ih_l3_reverse grad norm: 0.0041890740394592285\n",
      "lstm.weight_hh_l3_reverse grad norm: 0.0012915530242025852\n",
      "lstm.bias_ih_l3_reverse grad norm: 0.009323948994278908\n",
      "lstm.bias_hh_l3_reverse grad norm: 0.009323948062956333\n",
      "lstm.weight_ih_l4 grad norm: 0.014585752040147781\n",
      "lstm.weight_hh_l4 grad norm: 0.00749950809404254\n",
      "lstm.bias_ih_l4 grad norm: 0.03295409306883812\n",
      "lstm.bias_hh_l4 grad norm: 0.03295409306883812\n",
      "lstm.weight_ih_l4_reverse grad norm: 0.014980059117078781\n",
      "lstm.weight_hh_l4_reverse grad norm: 0.004400774370878935\n",
      "lstm.bias_ih_l4_reverse grad norm: 0.03397384658455849\n",
      "lstm.bias_hh_l4_reverse grad norm: 0.03397384658455849\n",
      "lstm.weight_ih_l5 grad norm: 0.05398128181695938\n",
      "lstm.weight_hh_l5 grad norm: 0.026839403435587883\n",
      "lstm.bias_ih_l5 grad norm: 0.11788318306207657\n",
      "lstm.bias_hh_l5 grad norm: 0.11788317561149597\n",
      "lstm.weight_ih_l5_reverse grad norm: 0.04543125629425049\n",
      "lstm.weight_hh_l5_reverse grad norm: 0.008586478419601917\n",
      "lstm.bias_ih_l5_reverse grad norm: 0.1012001782655716\n",
      "lstm.bias_hh_l5_reverse grad norm: 0.1012001782655716\n",
      "lstm.weight_ih_l6 grad norm: 0.21125857532024384\n",
      "lstm.weight_hh_l6 grad norm: 0.12833844125270844\n",
      "lstm.bias_ih_l6 grad norm: 0.47973892092704773\n",
      "lstm.bias_hh_l6 grad norm: 0.47973892092704773\n",
      "lstm.weight_ih_l6_reverse grad norm: 0.12436791509389877\n",
      "lstm.weight_hh_l6_reverse grad norm: 0.0\n",
      "lstm.bias_ih_l6_reverse grad norm: 0.30265215039253235\n",
      "lstm.bias_hh_l6_reverse grad norm: 0.30265215039253235\n"
     ]
    }
   ],
   "source": [
    "for name, param in bb_enc.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name} grad norm: {param.grad.norm()}\")\n",
    "    else:\n",
    "        print(f\"{name} grad is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight grad norm: 4.2484352889005095e-05\n",
      "lstm.weight_ih_l0 grad norm: 0.0003254949115216732\n",
      "lstm.weight_hh_l0 grad norm: 7.605506834806874e-05\n",
      "lstm.bias_ih_l0 grad norm: 0.0003012344823218882\n",
      "lstm.bias_hh_l0 grad norm: 0.0003012344823218882\n",
      "lstm.weight_ih_l0_reverse grad norm: 0.00032709658262319863\n",
      "lstm.weight_hh_l0_reverse grad norm: 7.603189442306757e-05\n",
      "lstm.bias_ih_l0_reverse grad norm: 0.000313809810904786\n",
      "lstm.bias_hh_l0_reverse grad norm: 0.000313809810904786\n",
      "lstm.weight_ih_l1 grad norm: 0.000558680621907115\n",
      "lstm.weight_hh_l1 grad norm: 0.00022624272969551384\n",
      "lstm.bias_ih_l1 grad norm: 0.0010487716645002365\n",
      "lstm.bias_hh_l1 grad norm: 0.0010487715480849147\n",
      "lstm.weight_ih_l1_reverse grad norm: 0.0004790965758729726\n",
      "lstm.weight_hh_l1_reverse grad norm: 0.00016279509873129427\n",
      "lstm.bias_ih_l1_reverse grad norm: 0.0009165560477413237\n",
      "lstm.bias_hh_l1_reverse grad norm: 0.0009165561059489846\n",
      "lstm.weight_ih_l2 grad norm: 0.0014243311015889049\n",
      "lstm.weight_hh_l2 grad norm: 0.0006491430685855448\n",
      "lstm.bias_ih_l2 grad norm: 0.0031884764321148396\n",
      "lstm.bias_hh_l2 grad norm: 0.003188476664945483\n",
      "lstm.weight_ih_l2_reverse grad norm: 0.0012144839856773615\n",
      "lstm.weight_hh_l2_reverse grad norm: 0.000511831371113658\n",
      "lstm.bias_ih_l2_reverse grad norm: 0.0027420001570135355\n",
      "lstm.bias_hh_l2_reverse grad norm: 0.0027420001570135355\n",
      "lstm.weight_ih_l3 grad norm: 0.005598713643848896\n",
      "lstm.weight_hh_l3 grad norm: 0.002777466317638755\n",
      "lstm.bias_ih_l3 grad norm: 0.012291979975998402\n",
      "lstm.bias_hh_l3 grad norm: 0.012291979975998402\n",
      "lstm.weight_ih_l3_reverse grad norm: 0.0041890740394592285\n",
      "lstm.weight_hh_l3_reverse grad norm: 0.0012915530242025852\n",
      "lstm.bias_ih_l3_reverse grad norm: 0.009323948994278908\n",
      "lstm.bias_hh_l3_reverse grad norm: 0.009323948062956333\n",
      "lstm.weight_ih_l4 grad norm: 0.014585752040147781\n",
      "lstm.weight_hh_l4 grad norm: 0.00749950809404254\n",
      "lstm.bias_ih_l4 grad norm: 0.03295409306883812\n",
      "lstm.bias_hh_l4 grad norm: 0.03295409306883812\n",
      "lstm.weight_ih_l4_reverse grad norm: 0.014980059117078781\n",
      "lstm.weight_hh_l4_reverse grad norm: 0.004400774370878935\n",
      "lstm.bias_ih_l4_reverse grad norm: 0.03397384658455849\n",
      "lstm.bias_hh_l4_reverse grad norm: 0.03397384658455849\n",
      "lstm.weight_ih_l5 grad norm: 0.05398128181695938\n",
      "lstm.weight_hh_l5 grad norm: 0.026839403435587883\n",
      "lstm.bias_ih_l5 grad norm: 0.11788318306207657\n",
      "lstm.bias_hh_l5 grad norm: 0.11788317561149597\n",
      "lstm.weight_ih_l5_reverse grad norm: 0.04543125629425049\n",
      "lstm.weight_hh_l5_reverse grad norm: 0.008586478419601917\n",
      "lstm.bias_ih_l5_reverse grad norm: 0.1012001782655716\n",
      "lstm.bias_hh_l5_reverse grad norm: 0.1012001782655716\n",
      "lstm.weight_ih_l6 grad norm: 0.21125857532024384\n",
      "lstm.weight_hh_l6 grad norm: 0.12833844125270844\n",
      "lstm.bias_ih_l6 grad norm: 0.47973892092704773\n",
      "lstm.bias_hh_l6 grad norm: 0.47973892092704773\n",
      "lstm.weight_ih_l6_reverse grad norm: 0.12436791509389877\n",
      "lstm.weight_hh_l6_reverse grad norm: 0.0\n",
      "lstm.bias_ih_l6_reverse grad norm: 0.30265215039253235\n",
      "lstm.bias_hh_l6_reverse grad norm: 0.30265215039253235\n"
     ]
    }
   ],
   "source": [
    "for name, param in bb_enc.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name} grad norm: {param.grad.norm()}\")\n",
    "    else:\n",
    "        print(f\"{name} grad is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in integrated.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(\"not\", param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'grad'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: _1\n",
      "op: *\n",
      "b: 5.0e-1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_a_op_b(input_string):\n",
    "    \n",
    "\n",
    "    # Find and replace expressions within parentheses with a placeholder\n",
    "    placeholder = '__PLACEHOLDER__'\n",
    "    flag_par = 0\n",
    "    while '(' in input_string and ')' in input_string:\n",
    "        flag_par = 1\n",
    "        # Find the innermost expression within parentheses\n",
    "        inner_expr = re.search(r'\\([^)]*\\)', input_string).group(0)\n",
    "        \n",
    "        # Replace the inner expression with a placeholder\n",
    "        input_string = input_string.replace(inner_expr, placeholder)\n",
    "\n",
    "    # Define the original pattern\n",
    "    original_pattern = r\"([-+]?\\b\\d+(\\.\\d*)?(e[+-]?\\d+)?\\b|\\b\\w+\\b|\\[\\s*\\d+(\\s*,\\s*\\d+)*\\s*\\])\\s*([+\\-*/])\\s*([-+]?\\b\\d+(\\.\\d*)?(e[+-]?\\d+)?\\b|\\b\\w+\\b|\\[\\s*\\d+(\\s*,\\s*\\d+)*\\s*\\])\"\n",
    "\n",
    "    # Find the first match in the modified input string\n",
    "    match = re.search(original_pattern, input_string)\n",
    "\n",
    "    if match:\n",
    "        # Extract a, op, b from the match\n",
    "        a = match.group(1)\n",
    "        op = match.group(5)\n",
    "        b = match.group(6)\n",
    "\n",
    "        # Replace the placeholder back with the original expression\n",
    "        if flag_par:\n",
    "            a = a.replace(placeholder, inner_expr)\n",
    "            b = b.replace(placeholder, inner_expr)\n",
    "\n",
    "        return a, op, b\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "input_string = \"_1 * 5.0e-1\"\n",
    "result = extract_a_op_b(input_string)\n",
    "\n",
    "if result:\n",
    "    a, op, b = result\n",
    "    print(\"a:\", a)\n",
    "    print(\"op:\", op)\n",
    "    print(\"b:\", b)\n",
    "else:\n",
    "    print(\"No match found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab = np.array(['a', 'b', 'c', 'a'])\n",
    "vocab = np.unique(vocab)\n",
    "word_to_idx = dict(zip(vocab, np.arange(len(vocab))))\n",
    "idx_to_word = dict(zip(np.arange(len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
